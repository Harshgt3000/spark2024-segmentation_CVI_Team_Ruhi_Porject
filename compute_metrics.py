#!/usr/bin/env python3
"""Compute confusion matrix and detailed metrics"""

import os
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
from transformers import SegformerForSemanticSegmentation
from tqdm import tqdm
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# Configuration
DATA_DIR = "/scratch/users/hchaurasia/spark2024/data"
CHECKPOINT = "/scratch/users/hchaurasia/spark2024/outputs/segformer_pseudo_20260109_123826/best_model.pth"
OUTPUT_DIR = "/scratch/users/hchaurasia/spark2024/report_figures"

# Find checkpoint if needed
if not os.path.exists(CHECKPOINT):
    import glob
    checkpoints = glob.glob("/scratch/users/hchaurasia/spark2024/outputs/*/best_model.pth")
    CHECKPOINT = sorted(checkpoints)[-1] if checkpoints else None
    print(f"Using: {CHECKPOINT}")

os.makedirs(OUTPUT_DIR, exist_ok=True)

# Load model
device = torch.device('cuda')
model = SegformerForSemanticSegmentation.from_pretrained(
    "nvidia/segformer-b5-finetuned-ade-640-640",
    num_labels=3,
    ignore_mismatched_sizes=True
)
checkpoint = torch.load(CHECKPOINT, map_location=device)
state_dict = {k.replace("module.", ""): v for k, v in checkpoint.items()}
model.load_state_dict(state_dict, strict=False)
model.to(device)
model.eval()
print("Model loaded!")

# Find validation images
val_images = []
images_dir = os.path.join(DATA_DIR, 'images')
for spacecraft in os.listdir(images_dir):
    val_dir = os.path.join(images_dir, spacecraft, 'val')
    mask_dir = os.path.join(DATA_DIR, 'mask', spacecraft, 'val')
    if os.path.exists(val_dir) and os.path.exists(mask_dir):
        for img_name in os.listdir(val_dir):
            if img_name.endswith('_img.jpg'):
                img_path = os.path.join(val_dir, img_name)
                mask_path = os.path.join(mask_dir, img_name.replace('_img.jpg', '_layer.jpg'))
                if os.path.exists(mask_path):
                    val_images.append((img_path, mask_path))

print(f"Found {len(val_images)} validation images")

# Limit for speed (process 1000 images)
val_images = val_images[:1000]

# Initialize confusion matrix
num_classes = 3
class_names = ['Background', 'Spacecraft Body', 'Solar Panel']
confusion_matrix = np.zeros((num_classes, num_classes), dtype=np.int64)

# Process images
for img_path, mask_path in tqdm(val_images, desc="Evaluating"):
    image = Image.open(img_path).convert('RGB')
    img_array = np.array(image)
    
    gt_mask = np.array(Image.open(mask_path))
    gt_classes = np.zeros(gt_mask.shape[:2], dtype=np.uint8)
    gt_classes[(gt_mask[:,:,0] > 200) & (gt_mask[:,:,2] < 50)] = 1
    gt_classes[(gt_mask[:,:,2] > 200) & (gt_mask[:,:,0] < 50)] = 2
    
    with torch.no_grad():
        img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).float() / 255.0
        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
        img_tensor = (img_tensor - mean) / std
        img_tensor = img_tensor.unsqueeze(0).to(device)
        
        outputs = model(img_tensor)
        logits = outputs.logits
        logits = F.interpolate(logits, size=gt_classes.shape, mode='bilinear', align_corners=False)
        pred = logits.argmax(dim=1).squeeze().cpu().numpy()
    
    for i in range(num_classes):
        for j in range(num_classes):
            confusion_matrix[i, j] += np.sum((gt_classes == i) & (pred == j))

# Compute IoU
intersection = np.diag(confusion_matrix)
union = confusion_matrix.sum(axis=1) + confusion_matrix.sum(axis=0) - intersection
class_iou = intersection / (union + 1e-6) * 100
mean_iou = np.mean(class_iou)

# Print results
print("\n" + "="*50)
print("FINAL EVALUATION RESULTS")
print("="*50)
print(f"\nPer-Class IoU:")
for i, name in enumerate(class_names):
    print(f"  {name}: {class_iou[i]:.2f}%")
print(f"\nMean IoU: {mean_iou:.2f}%")

# Save to file
with open(os.path.join(OUTPUT_DIR, 'final_metrics.txt'), 'w') as f:
    f.write("SPARK 2024 Task 2 - Final Metrics\n")
    f.write("="*50 + "\n\n")
    f.write("Per-Class IoU:\n")
    for i, name in enumerate(class_names):
        f.write(f"  {name}: {class_iou[i]:.2f}%\n")
    f.write(f"\nMean IoU: {mean_iou:.2f}%\n")
    f.write(f"Test Score (Codabench): 88.5%\n")
    f.write(f"\nConfusion Matrix:\n")
    f.write(str(confusion_matrix))

# Plot confusion matrix
fig, ax = plt.subplots(figsize=(10, 8))
cm_normalized = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1, keepdims=True) * 100

im = ax.imshow(cm_normalized, cmap='Blues')
ax.figure.colorbar(im, ax=ax, label='Percentage (%)')
ax.set(xticks=np.arange(num_classes),
       yticks=np.arange(num_classes),
       xticklabels=class_names,
       yticklabels=class_names,
       ylabel='True Label',
       xlabel='Predicted Label')

plt.setp(ax.get_xticklabels(), rotation=45, ha="right")

for i in range(num_classes):
    for j in range(num_classes):
        ax.text(j, i, f'{cm_normalized[i, j]:.1f}%',
               ha="center", va="center",
               color="white" if cm_normalized[i, j] > 50 else "black",
               fontsize=14, fontweight='bold')

ax.set_title('Confusion Matrix', fontsize=14)
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix.png'), dpi=150, bbox_inches='tight')
print(f"\nConfusion matrix saved!")

# Bar chart
fig, ax = plt.subplots(figsize=(10, 6))
colors = ['#2c3e50', '#e74c3c', '#3498db']
bars = ax.bar(class_names, class_iou, color=colors, edgecolor='black', linewidth=2)
ax.set_ylabel('IoU (%)', fontsize=12)
ax.set_title('Per-Class IoU Performance', fontsize=14)
ax.set_ylim([0, 105])
ax.axhline(y=mean_iou, color='green', linestyle='--', linewidth=2, label=f'Mean: {mean_iou:.1f}%')
ax.legend()

for bar, iou in zip(bars, class_iou):
    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 1,
           f'{iou:.1f}%', ha='center', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, 'per_class_iou.png'), dpi=150, bbox_inches='tight')
print("Per-class IoU chart saved!")

print(f"\nâœ“ All outputs in: {OUTPUT_DIR}")
